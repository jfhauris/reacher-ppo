{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections import namedtuple, deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Size of each action: 4\n",
      "There are 1 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726671e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"Reacher_single\")\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUMBER_OF_AGENTS = states.shape[0]\n",
    "STATE_SIZE = state_size\n",
    "ACTION_SIZE = action_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def soft_update(target, source, tau):\n",
    "    for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "        target_param.data.copy_(target_param.data * (1.0 - tau) + param.data * tau)\n",
    "\n",
    "def hard_update(target, source):\n",
    "    for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "        target_param.data.copy_(param.data)\n",
    "\n",
    "\"\"\"\n",
    "From: https://github.com/pytorch/pytorch/issues/1959\n",
    "There's an official LayerNorm implementation in pytorch now, but it hasn't been included in \n",
    "pip version yet. This is a temporary version\n",
    "This slows down training by a bit\n",
    "\"\"\"\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, num_features, eps=1e-5, affine=True):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.affine = affine\n",
    "        self.eps = eps\n",
    "\n",
    "        if self.affine:\n",
    "            self.gamma = nn.Parameter(torch.Tensor(num_features).uniform_())\n",
    "            self.beta = nn.Parameter(torch.zeros(num_features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        shape = [-1] + [1] * (x.dim() - 1)\n",
    "        mean = x.view(x.size(0), -1).mean(1).view(*shape)\n",
    "        std = x.view(x.size(0), -1).std(1).view(*shape)\n",
    "\n",
    "        y = (x - mean) / (std + self.eps)\n",
    "        if self.affine:\n",
    "            shape = [1, -1] + [1] * (x.dim() - 2)\n",
    "            y = self.gamma.view(*shape) * y + self.beta.view(*shape)\n",
    "        return y\n",
    "\n",
    "nn.LayerNorm = LayerNorm\n",
    "\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, hidden_size, num_inputs, action_space):\n",
    "        super(Actor, self).__init__()\n",
    "        self.action_space = action_space\n",
    "        num_outputs = action_space.shape[0]\n",
    "\n",
    "        self.linear1 = nn.Linear(num_inputs, hidden_size)\n",
    "        self.ln1 = nn.LayerNorm(hidden_size)\n",
    "\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.ln2 = nn.LayerNorm(hidden_size)\n",
    "\n",
    "        self.mu = nn.Linear(hidden_size, num_outputs)\n",
    "        self.mu.weight.data.mul_(0.1)\n",
    "        self.mu.bias.data.mul_(0.1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs\n",
    "        x = self.linear1(x)\n",
    "        x = self.ln1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.ln2(x)\n",
    "        x = F.relu(x)\n",
    "        mu = F.tanh(self.mu(x))\n",
    "        return mu\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, hidden_size, num_inputs, action_space):\n",
    "        super(Critic, self).__init__()\n",
    "        self.action_space = action_space\n",
    "        num_outputs = action_space.shape[0]\n",
    "\n",
    "        self.linear1 = nn.Linear(num_inputs, hidden_size)\n",
    "        self.ln1 = nn.LayerNorm(hidden_size)\n",
    "\n",
    "        self.linear2 = nn.Linear(hidden_size+num_outputs, hidden_size)\n",
    "        self.ln2 = nn.LayerNorm(hidden_size)\n",
    "\n",
    "        self.V = nn.Linear(hidden_size, 1)\n",
    "        self.V.weight.data.mul_(0.1)\n",
    "        self.V.bias.data.mul_(0.1)\n",
    "\n",
    "    def forward(self, inputs, actions):\n",
    "        x = inputs\n",
    "        x = self.linear1(x)\n",
    "        x = self.ln1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = torch.cat((x, actions), 1)\n",
    "        x = self.linear2(x)\n",
    "        x = self.ln2(x)\n",
    "        x = F.relu(x)\n",
    "        V = self.V(x)\n",
    "        return V\n",
    "\n",
    "class DDPG(object):\n",
    "    def __init__(self, gamma, tau, hidden_size, num_inputs, action_space):\n",
    "\n",
    "        self.num_inputs = num_inputs\n",
    "        self.action_space = action_space\n",
    "\n",
    "        self.actor = Actor(hidden_size, self.num_inputs, self.action_space)\n",
    "        self.actor_target = Actor(hidden_size, self.num_inputs, self.action_space)\n",
    "        self.actor_perturbed = Actor(hidden_size, self.num_inputs, self.action_space)\n",
    "        self.actor_optim = Adam(self.actor.parameters(), lr=1e-4)\n",
    "\n",
    "        self.critic = Critic(hidden_size, self.num_inputs, self.action_space)\n",
    "        self.critic_target = Critic(hidden_size, self.num_inputs, self.action_space)\n",
    "        self.critic_optim = Adam(self.critic.parameters(), lr=1e-3)\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "\n",
    "        hard_update(self.actor_target, self.actor)  # Make sure target is with the same weight\n",
    "        hard_update(self.critic_target, self.critic)\n",
    "\n",
    "\n",
    "    def select_action(self, state, action_noise=None, param_noise=None):\n",
    "        self.actor.eval()\n",
    "        if param_noise is not None: \n",
    "            mu = self.actor_perturbed((Variable(state)))\n",
    "        else:\n",
    "            mu = self.actor((Variable(state)))\n",
    "\n",
    "        self.actor.train()\n",
    "        mu = mu.data\n",
    "\n",
    "        if action_noise is not None:\n",
    "            mu += torch.Tensor(action_noise.noise())\n",
    "\n",
    "        return mu.clamp(-1, 1)\n",
    "\n",
    "\n",
    "    def update_parameters(self, batch):\n",
    "        state_batch = Variable(torch.cat(batch.state))\n",
    "        action_batch = Variable(torch.cat(batch.action))\n",
    "        reward_batch = Variable(torch.cat(batch.reward))\n",
    "        mask_batch = Variable(torch.cat(batch.mask))\n",
    "        next_state_batch = Variable(torch.cat(batch.next_state))\n",
    "        \n",
    "        next_action_batch = self.actor_target(next_state_batch)\n",
    "        next_state_action_values = self.critic_target(next_state_batch, next_action_batch)\n",
    "\n",
    "        reward_batch = reward_batch.unsqueeze(1)\n",
    "        mask_batch = mask_batch.unsqueeze(1)\n",
    "        expected_state_action_batch = reward_batch + (self.gamma * mask_batch * next_state_action_values)\n",
    "\n",
    "        self.critic_optim.zero_grad()\n",
    "\n",
    "        state_action_batch = self.critic((state_batch), (action_batch))\n",
    "\n",
    "        value_loss = F.mse_loss(state_action_batch, expected_state_action_batch)\n",
    "        value_loss.backward()\n",
    "        self.critic_optim.step()\n",
    "\n",
    "        self.actor_optim.zero_grad()\n",
    "\n",
    "        policy_loss = -self.critic((state_batch),self.actor((state_batch)))\n",
    "\n",
    "        policy_loss = policy_loss.mean()\n",
    "        policy_loss.backward()\n",
    "        self.actor_optim.step()\n",
    "\n",
    "        soft_update(self.actor_target, self.actor, self.tau)\n",
    "        soft_update(self.critic_target, self.critic, self.tau)\n",
    "\n",
    "        return value_loss.item(), policy_loss.item()\n",
    "\n",
    "    def perturb_actor_parameters(self, param_noise):\n",
    "        \"\"\"Apply parameter noise to actor model, for exploration\"\"\"\n",
    "        hard_update(self.actor_perturbed, self.actor)\n",
    "        params = self.actor_perturbed.state_dict()\n",
    "        for name in params:\n",
    "            if 'ln' in name: \n",
    "                pass \n",
    "            param = params[name]\n",
    "            param += torch.randn(param.shape) * param_noise.current_stddev\n",
    "\n",
    "    def save_model(self, env_name, suffix=\"\", actor_path=None, critic_path=None):\n",
    "        if not os.path.exists('models/'):\n",
    "            os.makedirs('models/')\n",
    "\n",
    "        if actor_path is None:\n",
    "            actor_path = \"models/ddpg_actor_{}_{}\".format(env_name, suffix) \n",
    "        if critic_path is None:\n",
    "            critic_path = \"models/ddpg_critic_{}_{}\".format(env_name, suffix) \n",
    "        print('Saving models to {} and {}'.format(actor_path, critic_path))\n",
    "        torch.save(self.actor.state_dict(), actor_path)\n",
    "        torch.save(self.critic.state_dict(), critic_path)\n",
    "\n",
    "    def load_model(self, actor_path, critic_path):\n",
    "        print('Loading models from {} and {}'.format(actor_path, critic_path))\n",
    "        if actor_path is not None:\n",
    "            self.actor.load_state_dict(torch.load(actor_path))\n",
    "        if critic_path is not None: \n",
    "            self.critic.load_state_dict(torch.load(critic_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ddpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1843cfb1a5ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mddpg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDDPG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnaf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNAF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnormalized_actions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNormalizedActions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ddpg'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import math\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from tqdm import tqdm\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import torch\n",
    "from naf import NAF\n",
    "from normalized_actions import NormalizedActions\n",
    "from ounoise import OUNoise\n",
    "from param_noise import AdaptiveParamNoiseSpec, ddpg_distance_metric\n",
    "from replay_memory import ReplayMemory, Transition\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch REINFORCE example')\n",
    "parser.add_argument('--algo', default='NAF',\n",
    "                    help='algorithm to use: DDPG | NAF')\n",
    "parser.add_argument('--env-name', default=\"HalfCheetah-v2\",\n",
    "                    help='name of the environment to run')\n",
    "parser.add_argument('--gamma', type=float, default=0.99, metavar='G',\n",
    "                    help='discount factor for reward (default: 0.99)')\n",
    "parser.add_argument('--tau', type=float, default=0.001, metavar='G',\n",
    "                    help='discount factor for model (default: 0.001)')\n",
    "parser.add_argument('--ou_noise', type=bool, default=True)\n",
    "parser.add_argument('--param_noise', type=bool, default=False)\n",
    "parser.add_argument('--noise_scale', type=float, default=0.3, metavar='G',\n",
    "                    help='initial noise scale (default: 0.3)')\n",
    "parser.add_argument('--final_noise_scale', type=float, default=0.3, metavar='G',\n",
    "                    help='final noise scale (default: 0.3)')\n",
    "parser.add_argument('--exploration_end', type=int, default=100, metavar='N',\n",
    "                    help='number of episodes with noise (default: 100)')\n",
    "parser.add_argument('--seed', type=int, default=4, metavar='N',\n",
    "                    help='random seed (default: 4)')\n",
    "parser.add_argument('--batch_size', type=int, default=128, metavar='N',\n",
    "                    help='batch size (default: 128)')\n",
    "parser.add_argument('--num_steps', type=int, default=1000, metavar='N',\n",
    "                    help='max episode length (default: 1000)')\n",
    "parser.add_argument('--num_episodes', type=int, default=1000, metavar='N',\n",
    "                    help='number of episodes (default: 1000)')\n",
    "parser.add_argument('--hidden_size', type=int, default=128, metavar='N',\n",
    "                    help='number of episodes (default: 128)')\n",
    "parser.add_argument('--updates_per_step', type=int, default=5, metavar='N',\n",
    "                    help='model updates per simulator step (default: 5)')\n",
    "parser.add_argument('--replay_size', type=int, default=1000000, metavar='N',\n",
    "                    help='size of replay buffer (default: 1000000)')\n",
    "args = parser.parse_args()\n",
    "\n",
    "env = NormalizedActions(gym.make(args.env_name))\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "env.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "if args.algo == \"NAF\":\n",
    "    agent = NAF(args.gamma, args.tau, args.hidden_size,\n",
    "                      env.observation_space.shape[0], env.action_space)\n",
    "else:\n",
    "    agent = DDPG(args.gamma, args.tau, args.hidden_size,\n",
    "                      env.observation_space.shape[0], env.action_space)\n",
    "\n",
    "memory = ReplayMemory(args.replay_size)\n",
    "\n",
    "ounoise = OUNoise(env.action_space.shape[0]) if args.ou_noise else None\n",
    "param_noise = AdaptiveParamNoiseSpec(initial_stddev=0.05, \n",
    "    desired_action_stddev=args.noise_scale, adaptation_coefficient=1.05) if args.param_noise else None\n",
    "\n",
    "rewards = []\n",
    "total_numsteps = 0\n",
    "updates = 0\n",
    "\n",
    "for i_episode in range(args.num_episodes):\n",
    "    state = torch.Tensor([env.reset()])\n",
    "\n",
    "    if args.ou_noise: \n",
    "        ounoise.scale = (args.noise_scale - args.final_noise_scale) * max(0, args.exploration_end -\n",
    "                                                                      i_episode) / args.exploration_end + args.final_noise_scale\n",
    "        ounoise.reset()\n",
    "\n",
    "    if args.param_noise and args.algo == \"DDPG\":\n",
    "        agent.perturb_actor_parameters(param_noise)\n",
    "\n",
    "    episode_reward = 0\n",
    "    while True:\n",
    "        action = agent.select_action(state, ounoise, param_noise)\n",
    "        next_state, reward, done, _ = env.step(action.numpy()[0])\n",
    "        total_numsteps += 1\n",
    "        episode_reward += reward\n",
    "\n",
    "        action = torch.Tensor(action)\n",
    "        mask = torch.Tensor([not done])\n",
    "        next_state = torch.Tensor([next_state])\n",
    "        reward = torch.Tensor([reward])\n",
    "\n",
    "        memory.push(state, action, mask, next_state, reward)\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        if len(memory) > args.batch_size:\n",
    "            for _ in range(args.updates_per_step):\n",
    "                transitions = memory.sample(args.batch_size)\n",
    "                batch = Transition(*zip(*transitions))\n",
    "\n",
    "                value_loss, policy_loss = agent.update_parameters(batch)\n",
    "\n",
    "                writer.add_scalar('loss/value', value_loss, updates)\n",
    "                writer.add_scalar('loss/policy', policy_loss, updates)\n",
    "\n",
    "                updates += 1\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    writer.add_scalar('reward/train', episode_reward, i_episode)\n",
    "\n",
    "    # Update param_noise based on distance metric\n",
    "    if args.param_noise:\n",
    "        episode_transitions = memory.memory[memory.position-t:memory.position]\n",
    "        states = torch.cat([transition[0] for transition in episode_transitions], 0)\n",
    "        unperturbed_actions = agent.select_action(states, None, None)\n",
    "        perturbed_actions = torch.cat([transition[1] for transition in episode_transitions], 0)\n",
    "\n",
    "        ddpg_dist = ddpg_distance_metric(perturbed_actions.numpy(), unperturbed_actions.numpy())\n",
    "        param_noise.adapt(ddpg_dist)\n",
    "\n",
    "    rewards.append(episode_reward)\n",
    "    if i_episode % 10 == 0:\n",
    "        state = torch.Tensor([env.reset()])\n",
    "        episode_reward = 0\n",
    "        while True:\n",
    "            action = agent.select_action(state)\n",
    "\n",
    "            next_state, reward, done, _ = env.step(action.numpy()[0])\n",
    "            episode_reward += reward\n",
    "\n",
    "            next_state = torch.Tensor([next_state])\n",
    "\n",
    "            state = next_state\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        writer.add_scalar('reward/test', episode_reward, i_episode)\n",
    "\n",
    "        rewards.append(episode_reward)\n",
    "        print(\"Episode: {}, total numsteps: {}, reward: {}, average reward: {}\".format(i_episode, total_numsteps, rewards[-1], np.mean(rewards[-10:])))\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\n",
    "    \n",
    "    Attributes:\n",
    "        action_size (int): dimension of each action\n",
    "        buffer_size (int): maximum size of buffer\n",
    "        batch_size (int): size of each training batch\n",
    "        seed (int): random seed \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\"\"\"\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)  \n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "  \n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)\n",
    "    \n",
    "    \n",
    "def soft_update(target, source, tau):\n",
    "    for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "        target_param.data.copy_(target_param.data * (1.0 - tau) + param.data * tau)\n",
    "\n",
    "def hard_update(target, source):\n",
    "    for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "        target_param.data.copy_(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Actor, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, input_size * 2)\n",
    "        self.fc2 = nn.Linear(input_size * 2, input_size * 2)\n",
    "        self.fc3 = nn.Linear(input_size * 2, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class Critic(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        input_size = input_size + output_size\n",
    "        self.fc1 = nn.Linear(input_size, input_size * 2)\n",
    "        self.fc2 = nn.Linear(input_size * 2, input_size * 2)\n",
    "        self.fc3 = nn.Linear(input_size * 2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    \n",
    "class AdaptiveParamNoiseSpec(object):\n",
    "    def __init__(self, initial_stddev=0.1, desired_action_stddev=0.1, adoption_coefficient=1.01):\n",
    "        self.initial_stddev = initial_stddev\n",
    "        self.desired_action_stddev = desired_action_stddev\n",
    "        self.adoption_coefficient = adoption_coefficient\n",
    "\n",
    "        self.current_stddev = initial_stddev\n",
    "\n",
    "    def adapt(self, distance):\n",
    "        if distance > self.desired_action_stddev:\n",
    "            # Decrease stddev.\n",
    "            self.current_stddev /= self.adoption_coefficient\n",
    "        else:\n",
    "            # Increase stddev.\n",
    "            self.current_stddev *= self.adoption_coefficient\n",
    "\n",
    "    def get_stats(self):\n",
    "        stats = {\n",
    "            'param_noise_stddev': self.current_stddev,\n",
    "        }\n",
    "        return stats\n",
    "\n",
    "    def __repr__(self):\n",
    "        fmt = 'AdaptiveParamNoiseSpec(initial_stddev={}, desired_action_stddev={}, adoption_coefficient={})'\n",
    "        return fmt.format(self.initial_stddev, self.desired_action_stddev, self.adoption_coefficient)\n",
    "# run your own policy!\n",
    "# policy=Policy().to(device)\n",
    "# policy = Policy(STATE_SIZE, ACTION_SIZE).to(device)\n",
    "\n",
    "# we use the adam optimizer with learning rate 2e-4\n",
    "# optim.SGD is also possible\n",
    "# actor_optimizer = optim.Adam(policy.parameters(), lr=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 50\n",
      "0.0\n",
      "0.6999999843537807\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b00a0aaf2ddb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0msoft_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0msoft_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcritic_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mparam_noise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m300.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mrr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-2b7f11b469fb>\u001b[0m in \u001b[0;36msoft_update\u001b[0;34m(target, source, tau)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msoft_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtarget_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mtarget_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhard_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "actor = Actor(STATE_SIZE, ACTION_SIZE).to(device)\n",
    "actor_perturbed = Actor(STATE_SIZE, ACTION_SIZE).to(device)\n",
    "critic = Critic(STATE_SIZE, ACTION_SIZE).to(device)\n",
    "actor_target = Actor(STATE_SIZE, ACTION_SIZE).to(device)\n",
    "critic_target = Critic(STATE_SIZE, ACTION_SIZE).to(device)\n",
    "\n",
    "hard_update(actor_target, actor)\n",
    "hard_update(critic_target, critic)\n",
    "\n",
    "actor_optimizer = optim.Adam(actor.parameters(), lr=1e-3)\n",
    "critic_optimizer = optim.Adam(critic.parameters(), lr=1e-3)\n",
    "buffer = ReplayBuffer(ACTION_SIZE, 10000, 32, 0)\n",
    "\n",
    "param_noise = AdaptiveParamNoiseSpec()\n",
    "\n",
    "rr = []\n",
    "for e in range(1, 100 + 1):\n",
    "    if e % 10 == 0:\n",
    "        clear_output(True)\n",
    "        print(f\"Iteration {e}\")\n",
    "        \n",
    "    hard_update(actor_perturbed, actor)\n",
    "    params = actor_perturbed.state_dict()\n",
    "    for name in params:\n",
    "        if 'ln' in name: \n",
    "            pass \n",
    "        param = params[name]\n",
    "        param += torch.randn(param.shape) * param_noise.current_stddev\n",
    "        \n",
    "    env_info = env.reset(train_mode=True)[brain_name]\n",
    "    state = env_info.vector_observations\n",
    "    \n",
    "    r = []\n",
    "    for t in range(500):\n",
    "        state_tensor = torch.tensor(state).float()\n",
    "        raw_action = actor(state_tensor).squeeze().detach().numpy()\n",
    "        action = np.clip(raw_action, -1, 1)\n",
    "                    \n",
    "        env_info = env.step(action)[brain_name]\n",
    "        next_state = env_info.vector_observations\n",
    "        done = 1 if env_info.local_done else 0\n",
    "        reward = env_info.rewards\n",
    "        r.append(sum(reward))\n",
    "        \n",
    "        buffer.add(state, raw_action, reward, next_state, done)\n",
    "        if len(buffer) >= 64:\n",
    "            states, actions, rewards, next_states, dones = buffer.sample()\n",
    "            y = rewards + 0.9999 * critic_target(torch.cat((next_states, actor_target(next_states)), 1))\n",
    "            concat = torch.cat((states.float(), actions.float()), 1)\n",
    "            L = torch.mean(torch.sum(y - critic(concat)))\n",
    "\n",
    "            critic_optimizer.zero_grad()\n",
    "            L.backward()\n",
    "            critic_optimizer.step()\n",
    "            \n",
    "            J = - torch.mean(torch.sum(critic(concat)))\n",
    "            actor_optimizer.zero_grad()\n",
    "            J.backward()\n",
    "            actor_optimizer.step()\n",
    "            \n",
    "            soft_update(actor_target, actor, 0.9)\n",
    "            soft_update(critic_target, critic, 0.9)\n",
    "    param_noise.adapt(max(30 - sum(r), 0) / 300.0)\n",
    "    rr.append(sum(r))\n",
    "    print(sum(r))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(rr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from IPython.display import clear_output\n",
    "\n",
    "iters = 500\n",
    "tmax =  300\n",
    "gamma = 0.99\n",
    "epochs = 2\n",
    "epsilon = 0.1\n",
    "r = []\n",
    "# old_policy = deepcopy(policy)\n",
    "\n",
    "for i in range(iters):\n",
    "    if i % 10 == 0:\n",
    "        clear_output(True)\n",
    "        print(f\"Iteration {i}\")\n",
    "        if len(r) > 100:\n",
    "            print(f\"Last 100 rewards average {sum(r[-100:])/len(r[-100:])}\")\n",
    "    \n",
    "    all_rewards = []\n",
    "    env_info = env.reset(train_mode=True)[brain_name]\n",
    "    state = env_info.vector_observations\n",
    "    all_states = []\n",
    "    all_actions = []\n",
    "    \n",
    "    for t in range(tmax):\n",
    "        state_tensor = torch.tensor(state).float()\n",
    "        raw_actions = policy(state_tensor).squeeze().detach().numpy()\n",
    "        actions = np.clip(raw_actions, -1, 1)\n",
    "\n",
    "        env_info = env.step(actions)[brain_name]\n",
    "        next_states = env_info.vector_observations\n",
    "        dones = env_info.local_done  \n",
    "        rewards = env_info.rewards\n",
    "        \n",
    "        all_rewards.append(rewards)\n",
    "        all_states.append(state)\n",
    "        all_actions.append(raw_actions)\n",
    "        \n",
    "        state = next_states\n",
    "        if True in dones:\n",
    "            break\n",
    "    \n",
    "    all_rewards = np.array(all_rewards)\n",
    "    r.append(np.sum(all_rewards))\n",
    "    discounts = gamma ** np.arange(all_rewards.shape[0])\n",
    "    discounted_rewards = all_rewards * discounts.reshape((tmax, 1))\n",
    "    future_rewards = discounted_rewards[::-1].cumsum(axis=0)[::-1]\n",
    "    future_rewards = future_rewards.reshape((tmax, NUMBER_OF_AGENTS, 1))\n",
    "    \n",
    "    mean = np.mean(future_rewards, axis=1)\n",
    "    std = np.std(future_rewards, axis=1) + 1.0e-10\n",
    "    rewards_normalized = (future_rewards - mean[:,np.newaxis])/std[:,np.newaxis]\n",
    "    \n",
    "    actions_tensor = torch.tensor(all_actions)\n",
    "    rewards_tensor = torch.tensor(rewards_normalized.copy(), dtype=torch.float)\n",
    "    for e in range(epochs):\n",
    "#         ratio = policy(torch.tensor(all_states).float()).squeeze().detach().numpy() /\n",
    "        new_policy = policy(torch.tensor(all_states).float())\n",
    "        ratio = (policy(torch.tensor(all_states).float()) / actions_tensor)\n",
    "        ratio = ratio * rewards_tensor\n",
    "        ratio = torch.mean(ratio)\n",
    "        clipped = torch.clamp(ratio, 1 - epsilon, 1 + epsilon)\n",
    "        \n",
    "        L = torch.min(ratio, clipped)\n",
    "        optimizer.zero_grad()\n",
    "        L.backward()\n",
    "        optimizer.step()\n",
    "        del L\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_trajectories(env, policy, number_of_agents, tmax=200, nrand=5):\n",
    "    \n",
    "    raw_action_list = []\n",
    "    state_list=[]\n",
    "    reward_list=[]\n",
    "    action_list=[]\n",
    "\n",
    "    env_info = env.reset(train_mode=True)[brain_name]\n",
    "    state = env_info.vector_observations\n",
    "    \n",
    "    # perform nrand random steps\n",
    "    for _ in range(nrand):\n",
    "        raw_actions = np.random.randn(NUMBER_OF_AGENTS, ACTION_SIZE)\n",
    "        actions = np.clip(raw_actions, -1, 1)\n",
    "\n",
    "        env_info = env.step(actions)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        rewards = env_info.rewards\n",
    "        \n",
    "    for t in range(tmax):\n",
    "        state_tensor = torch.tensor(states).float()\n",
    "        raw_actions = policy(state_tensor).squeeze().cpu().detach().numpy()\n",
    "        actions = np.clip(raw_actions, -1, 1)\n",
    "        \n",
    "        env_info = env.step(actions)[brain_name]\n",
    "        next_states = env_info.vector_observations\n",
    "        dones = env_info.local_done  \n",
    "        rewards = env_info.rewards\n",
    "\n",
    "\n",
    "        raw_action_list.append(raw_actions)\n",
    "        state_list.append(states)\n",
    "        reward_list.append(rewards)\n",
    "        action_list.append(actions)\n",
    "        \n",
    "        states = next_states\n",
    "        \n",
    "        # stop if any of the trajectories is done\n",
    "        # we want all the lists to be retangular\n",
    "        if True in dones:\n",
    "            break\n",
    "\n",
    "    # return pi_theta, states, actions, rewards, probability\n",
    "    return raw_actions, state_list, action_list, reward_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipped_surrogate(policy, old_probs, states, actions, rewards,\n",
    "                      discount = 0.995, epsilon=0.1, beta=0.01):\n",
    "\n",
    "    discount = discount**np.arange(len(rewards))\n",
    "    rewards = np.asarray(rewards)*discount[:,np.newaxis]\n",
    "    \n",
    "    rewards_future = rewards[::-1].cumsum(axis=0)[::-1]\n",
    "    mean = np.mean(rewards_future, axis=1)\n",
    "    std = np.std(rewards_future, axis=1) + 1.0e-10\n",
    "    rewards_normalized = (rewards_future - mean[:,np.newaxis])/std[:,np.newaxis]\n",
    "    \n",
    "    states = torch.tensor(states, dtype=torch.float, device=device)\n",
    "    actions = torch.tensor(actions, dtype=torch.int8, device=device)\n",
    "    old_probs = torch.tensor(old_probs, dtype=torch.float, device=device)\n",
    "    rewards = torch.tensor(rewards_normalized[:, :, np.newaxis], dtype=torch.float, device=device)\n",
    "    \n",
    "    new_probs = policy.forward(states)\n",
    "\n",
    "    division = new_probs / old_probs\n",
    "    p = torch.min(new_probs / old_probs, torch.clamp(new_probs / old_probs, 1 - epsilon, 1 + epsilon)) * rewards \n",
    "    entropy = -(new_probs*torch.log(old_probs+1.e-10) + (1.0-new_probs)*torch.log(1.0-old_probs+1.e-10))\n",
    "#     return torch.mean(p + beta*entropy)\n",
    "    return torch.mean(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# envs = parallelEnv('PongDeterministic-v4', n=8, seed=1234)\n",
    "\n",
    "# discount_rate = .99\n",
    "epsilon = 0.1\n",
    "beta = .01\n",
    "# tmax = 320\n",
    "# SGD_epoch = 4\n",
    "\n",
    "# # keep track of progress\n",
    "mean_rewards = []\n",
    "\n",
    "for e in range(100):\n",
    "    raw_actions, states, actions, rewards = collect_trajectories(env, policy, NUMBER_OF_AGENTS)\n",
    "    total_rewards = np.sum(rewards, axis=0)\n",
    "    L = - clipped_surrogate(policy, raw_actions, states, actions, rewards, epsilon=epsilon, beta=beta)\n",
    "    optimizer.zero_grad()\n",
    "    L.backward()\n",
    "    optimizer.step()\n",
    "    del L\n",
    "    \n",
    "    epsilon*=.999\n",
    "    beta*=.995\n",
    "    \n",
    "    mean_rewards.append(np.mean(total_rewards))\n",
    "\n",
    "    if (e+1)%20 ==0 :\n",
    "        print(\"Episode: {0:d}, score: {1:f}\".format(e+1,np.mean(total_rewards)))\n",
    "        print(total_rewards)\n",
    "\n",
    "\n",
    "\n",
    "#     # gradient ascent step\n",
    "#     for _ in range(SGD_epoch):\n",
    "        \n",
    "#         # uncomment to utilize your own clipped function!\n",
    "#         L = -clipped_surrogate(policy, old_probs, states, actions, rewards, epsilon=epsilon, beta=beta)\n",
    "\n",
    "# #         L = -pong_utils.clipped_surrogate(policy, old_probs, states, actions, rewards,\n",
    "# #                                           epsilon=epsilon, beta=beta)\n",
    "#         optimizer.zero_grad()\n",
    "#         L.backward()\n",
    "#         optimizer.step()\n",
    "#         del L\n",
    "    \n",
    "#     # the clipping parameter reduces as time goes on\n",
    "#     epsilon*=.999\n",
    "    \n",
    "#     # the regulation term also reduces\n",
    "#     # this reduces exploration in later runs\n",
    "#     beta*=.995\n",
    "    \n",
    "#     # get the average reward of the parallel environments\n",
    "#     mean_rewards.append(np.mean(total_rewards))\n",
    "    \n",
    "#     # display some progress every 20 iterations\n",
    "#     if (e+1)%20 ==0 :\n",
    "#         print(\"Episode: {0:d}, score: {1:f}\".format(e+1,np.mean(total_rewards)))\n",
    "#         print(total_rewards)\n",
    "        \n",
    "#     # update progress widget bar\n",
    "#     timer.update(e+1)\n",
    "    \n",
    "# timer.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name]      # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
